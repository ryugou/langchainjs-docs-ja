---
title: はじめに
slug: /how_to
sidebar_label: はじめに
tags: [langchainjs, how-to]
---

# 使い方ガイド

ここでは「どうやって ○○ するの？」というタイプの疑問に答えます。これらのガイドは目的志向かつ具体的で、特定のタスクを完了するのに役立ちます。概念的な説明は Conceptual Guides、端から端までの手順は Tutorials、クラスや関数の包括的説明は API Reference を参照してください。

## インストール

- LangChain パッケージをインストールする

## 主要機能

LangChain を使ううえで核となる機能のハイライトです。

- LLM から構造化データを返す

- チャットモデルでツールを呼び出す

- Runnable をストリーミングする

- LLM アプリをデバッグする

## LangChain Expression Language（LCEL）

LCEL は任意のカスタムチェーンを作成するための表現言語で、Runnable プロトコルの上に構築されています。

LCEL チートシート：主要な LCEL プリミティブのクイック概要

- Runnable を連結する（chain）

- Runnable をストリーミングする

- Runnable を並列実行する

- 実行時引数を Runnable に付与する

- カスタム関数を実行する

- あるステップから次のステップへ引数を渡す

- チェーンの状態（state）に値を追加する

- メッセージ履歴を追加する

- チェーン内の分岐・ルーティングを行う

- フォールバックを追加する

- 実行をキャンセルする

## コンポーネント

アプリを構築する際の基本的なビルディングブロックです。

### プロンプトテンプレート

ユーザー入力を言語モデルに渡せる形式へ整形します。

- フューショット例を使う

- チャットモデルでフューショット例を使う

- プロンプトテンプレートを部分的にフォーマットする

- 複数のプロンプトを合成する

### Example セレクタ

プロンプトに渡す適切なフューショット例を選択します。

- Exapmple セレクタを使う

- 長さ（トークン数等）で例を選ぶ

- 意味的類似度で例を選ぶ

- LangSmith の few-shot データセットから例を選ぶ

### チャットモデル

メッセージを受け取り、メッセージを出力する新しいタイプの言語モデルです。

- 関数／ツール呼び出しを行う

- 構造化出力を返すようにする

- モデル応答をキャッシュする

- カスタムチャットモデルクラスを作成する

- 対数確率（logprobs）を取得する

- 応答をストリーミングする

- トークン使用量を追跡する

- ツールの出力をチャットモデルへ渡す

- ツール呼び出しをストリーミングする

- フューショットでツール挙動を促す

- 特定のツール呼び出しを強制する

- 並列ツール呼び出しを無効化する

- 任意のモデルを 1 行で初期化する

### メッセージ

チャットモデルの入出力。メッセージは内容（content）と役割（role）を持ち、送信元を表します。

- メッセージをトリム（短縮）する

- メッセージをフィルタする

- 連続した同種メッセージをマージする

### LLMs

文字列を受け取り文字列を返す従来型の言語モデルです。

- 応答をキャッシュする

- カスタム LLM クラスを作成する

- 応答をストリーミングする

- トークン使用量を追跡する

### 出力パーサ

LLM の出力を受け取り、より構造化された形式へ変換します。

- 出力パーサで LLM 応答を構造化形式へ変換する

- JSON 出力をパースする

- XML 出力をパースする

- 出力パースのエラーを修正しようとする

### ドキュメントローダー

さまざまなソースからドキュメントを読み込みます。

- CSV データを読み込む

- ディレクトリからデータを読み込む

- PDF ファイルを読み込む

- カスタムドキュメントローダーを書く

- HTML データを読み込む

- Markdown データを読み込む

### テキストスプリッタ

ドキュメントを取得用のチャンクに分割します。

- 再帰的にテキストを分割する

- 文字単位で分割する

- コードを分割する

- トークン単位で分割する

### 埋め込みモデル

テキストを数値ベクトル表現に変換します。

- テキストデータを埋め込む

- 埋め込み結果をキャッシュする

### ベクトルストア

埋め込みを効率的に保存・検索できるデータベースです。

- ベクトルストアを作成・クエリする

# リトリーバ（Retrievers）

クエリを受け取り、関連ドキュメントを返します。

- ベクトルストアを使ってデータを取得する

- 複数のクエリを生成して取得性能を高める

- コンテキスト圧縮で取得データを圧縮する

- カスタムリトリーバクラスを書く

- 複数リトリーバの結果を結合する

- 1 ドキュメントあたり複数埋め込みを生成する

- チャンクに対して全文書を取得する

- メタデータフィルタを生成する

- 時間重み付きリトリーバを作成する

- 取得のレイテンシを削減する

### インデキシング

ベクトルストアを基データソースと同期させ続けるプロセスです。

- 再インデックスしてベクトルストアとデータソースの同期を保つ

# ツール

LangChain のツールは、言語モデルに渡す説明と、呼び出す関数の実装を含みます。

- ツールを作成する

- 組み込みツール／ツールキットを使う

- チャットモデルでツールを呼び出す

- ツール出力をチャットモデルに渡す

- フューショットでツール挙動を促す

- 実行時の値をツールへ渡す

- ツールのエラーを扱う

- 特定ツール呼び出しを強制する

- 並列ツール呼び出しを無効化する

- カスタムツール内で RunnableConfig にアクセスする

- カスタムツール内で子ランのイベントをストリームする

- ツールからアーティファクトを返す

- Runnable をツールへ変換する

- モデルにアドホックなツール呼び出し機能を付与する

### エージェント

:::caution
エージェントの詳細なハウツーは LangGraph のドキュメントを参照してください。
:::

- 旧 LangChain Agents（AgentExecutor）を使う

- 旧エージェントから LangGraph へ移行する

### コールバック

- LLM アプリ実行の各段階にフックを差し込みます。

- 実行時にコールバックを渡す

- モジュールへコールバックを取り付ける

- モジュールコンストラクタにコールバックを渡す

- カスタムコールバックハンドラを作る

- サーバレス環境でコールバックを await する

- カスタムコールバックイベントをディスパッチする

### カスタム

LangChain の全コンポーネントは容易に拡張できます。

- カスタムチャットモデルクラスを作る

- カスタム LLM クラスを作る

- カスタムリトリーバクラスを書く

- カスタムドキュメントローダーを書く

- カスタムコールバックハンドラを作る

- カスタムツールを定義する

- カスタムコールバックイベントをディスパッチする

## 生成 UI

- LLM 生成 UI を構築する

- エージェント的データをクライアントへストリームする

- 構造化出力をクライアントへストリームする

### マルチモーダル

- 複数モーダルデータを直接モデルへ渡す

- マルチモーダルプロンプトを使う

- マルチモーダルデータでツールを呼び出す

## ユースケース

用途別の詳細ガイドです。

### RAG による Q&A

外部データソースへ LLM を接続する手法。概要チュートリアルは該当ガイドを参照。

- チャット履歴を追加する

- ストリーミングする

- 参照元（sources）を返す

- 出典（citations）を返す

- ユーザー別のリトリーバルを行う

### 抽出

非構造テキストから構造化情報を抽出。概要は該当ガイドを参照。

- 参照例（reference examples）を使う

- 長文に対処する

- 関数呼び出しを使わずに抽出する

### チャットボット

LLM を用いた対話。概要チュートリアルは該当ガイドを参照。

- メモリを管理する

- リトリーバルを行う

- ツールを使う

### クエリ解析

リトリーバへ送るクエリを LLM で生成するタスク。概要は該当ガイドを参照。

- プロンプトに例を追加する

- クエリが生成されないケースを扱う

- 複数クエリを扱う

- 複数リトリーバを扱う

- フィルタを構築する

- 高カーディナリティのカテゴリ変数に対処する

### SQL・CSV 上での Q&A

表形式データに対する質問応答。概要は該当ガイドを参照。

- プロンプトで結果を改善する

- クエリ検証を行う

- 大規模データベースに対処する

### グラフデータベース上での Q&A

グラフ DB に対する質問応答。概要は該当ガイドを参照。

- 値をデータベースへマッピングする

- データベースにセマンティック層を追加する

- プロンプトで結果を改善する

- ナレッジグラフを構築する

## LangGraph.js

LangChain を拡張し、グラフのノードとエッジとしてステップをモデリングすることで、堅牢でステートフルなマルチアクターアプリを構築するためのフレームワークです。

LangGraph.js のドキュメントは別サイトにあります。How-to ガイドはそちらを参照してください。

## LangSmith

LLM アプリを詳細にトレース／監視／評価できます。LangChain や LangGraph.js とシームレスに統合され、チェーンの各ステップを検査・デバッグできます。

ドキュメントは別サイトにあります。LangChain に特に関連するセクションを以下にハイライトします。

### 評価

LLM アプリ開発では性能評価が不可欠です。LangSmith はデータセット作成から指標定義、評価器実行まで支援します。
→ 詳細は LangSmith の評価ハウツーガイド へ。

### トレーシング

チェーンやエージェント内部の可観測性を提供し、問題診断に不可欠です。

- LangChain でトレースする

- トレースにメタデータやタグを追加する

トレーシング全般のハウツーは LangSmith ドキュメント の該当セクションを参照してください。
